---
title: "R Notebook"
output: html_notebook
---

---
title: "R Notebook"
output: html_notebook
---




# Carregar pacotes necessários
```{r}

library(tidyverse)
library(qiime2R)
library(pheatmap)
library(dplyr)
library(tidyr)
library(ggplot2)
library(viridis)
library(ggrepel) # for offset labels
library(ggtree) # for visualizing phylogenetic trees
library(ape) # for manipulating phylogenetic trees
library(Hmisc)
library(writexl)
library(ggplot2)
library(reshape2)

```


```{r}
metadata <- read.csv("C:/Users/polia/OneDrive/Desktop/EstatisticaR/AgrUrbana/16S_AgriUrbana/metadados_raw_V01_local_nascimento2.csv", 
                     sep = ";", 
                     header = TRUE, 
                     stringsAsFactors = FALSE, 
                     fileEncoding = "UTF-8")

# Manter apenas as primeiras 130 linhas
metadata <- metadata[1:130, ]

# Remover a primeira coluna
metadata <- metadata[, -1]


# Remover quaisquer linhas completamente vazias (se necessário)
metadata <- metadata[rowSums(is.na(metadata)) != ncol(metadata), ]



# Exibir as primeiras linhas para verificar se os dados foram importados corretamente
head(metadata)

# Verifique os nomes das colunas para garantir que foram carregados corretamente
colnames(metadata)



SVs<-read_qza("C:/Users/polia/OneDrive/Desktop/EstatisticaR/AgrUrbana/16S_AgriUrbana/table.qza")$data
taxonomy<-read_qza("C:/Users/polia/OneDrive/Desktop/EstatisticaR/AgrUrbana/16S_AgriUrbana/taxonomy_silva.qza")$data
```

```{r}
#Filtrar SVs

# Substitui "-" por "." nos nomes das linhas do dataframe

colnames(SVs) <- gsub("-", ".", colnames(SVs))


# Filtra as linhas onde os nomes das linhas não terminam com ".F01"
SVs <- SVs[!grepl("\\.F01$", colnames(SVs)), , drop = FALSE]


# Selecionar colunas cujos nomes terminam com ".F00"
colunas_f00 <- grep("\\.F00$", colnames(SVs), value = TRUE)

# Filtrar o dataframe para manter apenas essas colunas
SVs <- SVs[, (grep("\\.F00$", colnames(SVs), value = TRUE))]

# Verificar o resultado
colnames(SVs)

```

```{r}
# Calcular o número de voluntários em que cada ASV está presente
asv_presence <- rowSums(SVs > 0)

# Filtrar ASVs presentes em pelo menos 13 voluntários
SVs_filtered <- SVs[asv_presence >= 13, ]

```


```{r}


# Normalizar para porcentagem
SVs_normalized <- apply(SVs_filtered, 2, function(x) x / sum(x) * 100)  # Converte para porcentagem

```


```{r}
# Transformar em data frame para manipulação
SVs_long <- SVs_normalized %>%
  as.data.frame() %>%
  rownames_to_column("Feature.ID") %>%
  gather(-Feature.ID, key = "Sample.id", value = "Abundance")

```


```{r}
# Aplicar transformação logarítmica

SVs_long <- SVs_long %>%
  mutate(NormAbundance = log10(Abundance + 0.01))  # Adiciona 0.01 para evitar log(0)

# Exportar para uma planilha
write.csv(SVs_long, "C:/Users/polia/OneDrive/Desktop/EstatisticaR/AgrUrbana/16S_AgriUrbana/Planilhas_UrbanAgri/SVs_normalized_log_transformed.csv", row.names = FALSE)



```


```{r}
library(ggplot2)
library(pheatmap)

# Converter de volta para formato largo para o heatmap
SVs_matrix <- SVs_long %>%
  select(Feature.ID, Sample.id, NormAbundance) %>%
  spread(key = Sample.id, value = NormAbundance, fill = 0) %>%
  column_to_rownames("Feature.ID")



# Definir a paleta de cores com branco no centro
color_palette <- colorRampPalette(c("blue", "white", "red"))(50)

# Gerar o heatmap com o ponto zero centralizado na cor branca
pheatmap(SVs_matrix, 
         clustering_method = "ward.D2",  # Método de clusterização
         clustering_distance_rows = "euclidean",  # Distância para ASVs
         clustering_distance_cols = "euclidean",  # Distância para amostras
         scale = "row",  # Escala por linha para melhor visualização
         main = "Heatmap de Abundância Normalizada e Log-transformada das ASVs",
         color = color_palette)

```



