---
title: "R Notebook"
output: html_notebook
---

```{r}
# Carregar pacotes necessários
library(tidyverse)


# Instalar microbiomeMarker via Bioconductor
BiocManager::install("microbiomeMarker")

library(microbiomeMarker)

library(qiime2R)
library(phyloseq)
install.packages("xfun")

library(tibble)

```



```{r}
#metadata <- read.csv("C:/Users/polia/OneDrive/Desktop/EstatisticaR/AgrUrbana/16S_AgriUrbana/metadados_raw_V01_local_nascimento2.csv", 
                     sep = ";", 
                     header = TRUE, 
                     stringsAsFactors = FALSE, 
                     fileEncoding = "UTF-8")

metadata <-metadados.raw

# Manter apenas as primeiras 130 linhas
metadata <- metadata[1:130, ]

# Remover a primeira coluna
metadata <- metadata[, -1]


# Remover quaisquer linhas completamente vazias (se necessário)
metadata <- metadata[rowSums(is.na(metadata)) != ncol(metadata), ]



# Exibir as primeiras linhas para verificar se os dados foram importados corretamente
head(metadata)

# Verifique os nomes das colunas para garantir que foram carregados corretamente
colnames(metadata)



SVs<-read_qza("C:/Users/polia/OneDrive/Desktop/EstatisticaR/AgrUrbana/16S_AgriUrbana/table.qza")$data
taxonomy<-read_qza("C:/Users/polia/OneDrive/Desktop/EstatisticaR/AgrUrbana/16S_AgriUrbana/taxonomy_silva.qza")$data
```

```{r}
#Filtrar SVs

# Substitui "-" por "." nos nomes das linhas do dataframe

colnames(SVs) <- gsub("-", ".", colnames(SVs))


# Filtra as linhas onde os nomes das linhas não terminam com ".F01"
SVs <- SVs[!grepl("\\.F01$", colnames(SVs)), , drop = FALSE]


# Selecionar colunas cujos nomes terminam com ".F00"
colunas_f00 <- grep("\\.F00$", colnames(SVs), value = TRUE)

# Filtrar o dataframe para manter apenas essas colunas
SVs <- SVs[, (grep("\\.F00$", colnames(SVs), value = TRUE))]

# Verificar o resultado
colnames(SVs)

```

```{r}
SVs <- ASV.table.raw

# Calcular o número de voluntários em que cada ASV está presente
asv_presence <- rowSums(SVs > 0)

# Filtrar ASVs presentes em pelo menos 13 voluntários
SVs_filtered <- SVs[asv_presence >= 13, ]

```


```{r}


# Normalizar para porcentagem
SVs_normalized <- apply(SVs_filtered, 2, function(x) x / sum(x) * 100)  # Converte para porcentagem

```


```{r}
# Transformar em data frame para manipulação
SVs_long <- SVs_normalized %>%
  as.data.frame() %>%
  rownames_to_column("Feature.ID") %>%
  gather(-Feature.ID, key = "Sample.id", value = "Abundance")

```


```{r}
# Aplicar transformação logarítmica

SVs_long <- SVs_long %>%
  mutate(NormAbundance = log10(Abundance + 0.01))  # Adiciona 0.01 para evitar log(0)

# Exportar para uma planilha
write.csv(SVs_long, "SVs_normalized_log_transformed.csv", row.names = FALSE)



```


```{r}
library(ggplot2)
library(pheatmap)

# Converter de volta para formato largo para o heatmap
SVs_matrix <- SVs_long %>%
  select(Feature.ID, Sample.id, NormAbundance) %>%
  spread(key = Sample.id, value = NormAbundance, fill = 0) %>%
  column_to_rownames("Feature.ID")



# Definir a paleta de cores com branco no centro
color_palette <- colorRampPalette(c("blue", "white", "red"))(50)

# Gerar o heatmap com o ponto zero centralizado na cor branca
pheatmap(SVs_matrix, 
         clustering_method = "ward.D2",  # Método de clusterização
         clustering_distance_rows = "euclidean",  # Distância para ASVs
         clustering_distance_cols = "euclidean",  # Distância para amostras
         scale = "row",  # Escala por linha para melhor visualização
         main = "Heatmap de Abundância Normalizada e Log-transformada das ASVs",
         color = color_palette)

```

```{r}
library(pheatmap)

# Selecionar as 50 ASVs mais abundantes
top_ASVs <- rowSums(SVs_matrix) %>% sort(decreasing = TRUE) %>% head(50) %>% names()
SVs_matrix_top <- SVs_matrix[top_ASVs, ]

# Criar a paleta de cores com branco centralizado
color_palette <- colorRampPalette(c("blue", "white", "red"))(100)

# Gerar o heatmap com as top 50 ASVs
pheatmap(SVs_matrix_top, 
         clustering_method = "ward.D2",
         clustering_distance_rows = "euclidean",
         clustering_distance_cols = "euclidean",
         scale = "row",
         main = "Heatmap das 50 ASVs Mais Abundantes (Normalizado e Log-transformado)",
         color = color_palette)


```



```{r}
library(dplyr)

# Calcular o IMC em metadata
metadata <- metadata %>%
  mutate(IMC = Weight / (Height^2))

metadata <- metadata %>%
  mutate(W_H_ratio = Waist / Hip)

# Visualizar o resultado para confirmar
glimpse(metadata)


# Remover as colunas indesejadas do metadata
metadata_filtered <- metadados.all %>%
  select(-c("Gravida", "Menopausa", "Raca", "Gravida", "Weight", "Height",  "Hip","WHR"                ))

str(metadata_filtered)


# Juntar ASVs_long com metadata filtrado
# Assumindo que a coluna de junção seja "Sample.id" em ASVs_long e "SampleID" em metadata_filtered
metadata_ASVs <- SVs_long %>%
  inner_join(metadata_filtered, by = c("Sample.id" = "Sample.id"))

```

```{r}
library(dplyr)

# Juntar o objeto taxonomy ao metadata_ASVs usando a coluna Feature.ID
metadata_ASVs <- metadata_ASVs %>%
  left_join(taxonomy %>% select(Feature.ID, Taxon, Confidence), by = "Feature.ID")

# Reorganizar para que Taxon seja a segunda coluna e Confidence a terceira
metadata_ASVs <- metadata_ASVs %>%
  select(Feature.ID, Taxon, Confidence, everything())

# Visualizar o resultado
metadata_ASVs

```

```{r}
# Reorganizar para que Sample.id seja a primeira coluna
metadata_ASVs <- metadata_ASVs %>%
  select(Sample.id, everything())

# Visualizar o resultado
glimpse(metadata_ASVs)

```

```{r}
library(dplyr)
library(ggplot2)

# Filtrar apenas colunas numéricas de metadata e manter Sample.id
numeric_metadata <- metadata %>%
  select(Sample.id, where(is.numeric))

# Preparar dados para o heatmap usando SVs_long e combinando com colunas numéricas de metadata
heatmap_data <- SVs_long %>%
  left_join(numeric_metadata, by = "Sample.id") %>%
  left_join(taxonomy, by = "Feature.ID") %>%
  mutate(Feature = paste(Feature.ID, Taxon)) %>%
  mutate(Feature = gsub("[kpcofgs]__", "", Feature))  # Remover prefixos na taxonomia

# Plotar o heatmap
ggplot(heatmap_data, aes(x = Sample.id, y = Feature, fill = NormAbundance)) +
  geom_tile() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_viridis_c(name = "NormAbundance") +
  labs(title = "Heatmap de Abundância Normalizada das ASVs", x = "Sample ID", y = "ASV (Feature.ID e Taxonomia)")

# Salvar o gráfico como PDF
ggsave("heatmap.pdf", height = 4, width = 11, device = "pdf")


```

```{r}
library(dplyr)
library(ggplot2)

# Filtrar apenas colunas numéricas de metadata e manter Sample.id
numeric_metadata <- metadata %>%
  select(Sample.id, where(is.numeric))

# Preparar dados para o heatmap usando SVs_long e combinando com colunas numéricas de metadata
heatmap_data <- SVs_long %>%
  left_join(numeric_metadata, by = "Sample.id") %>%
  left_join(taxonomy, by = "Feature.ID") 

# Plotar o heatmap
ggplot(heatmap_data, aes(x = Sample.id, y = Feature.ID, fill = NormAbundance)) +
  geom_tile() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_viridis_c(name = "NormAbundance") +
  labs(title = "Heatmap de Abundância Normalizada das ASVs", x = "Sample ID", y = "Feature.ID")

# Salvar o gráfico como PDF
ggsave("heatmap_larger.pdf", height = 10, width = 20, device = "pdf")


```

```{r}



library(dplyr)
library(tidyr)
library(pheatmap)
library(tibble)

# 1. Selecionar apenas colunas relevantes de saúde
health_data <- metadata_ASVs %>%
  dplyr::select(Sample.id, IL17A, IFNGamma, TNF, IL10, IL6, IL4, IL2, Age,
                Systolic, Diastolic, UREIA, CREATININA, HbA1c, COLESTEROL, LDL,
                HDL, VLDL, TRIGLICERIDES, TGO, TGP, GGT, GLICOSE, INSULINA, HOMA.IR, 
                PCR, BMI, TyG, VAI, QUICKI, METS_IR, W.H) %>%
  dplyr::rename(HOMA = HOMA.IR, IMC = BMI, W_H_ratio = W.H) %>%  # renomeando para corresponder ao uso posterior
  dplyr::distinct(Sample.id, .keep_all = TRUE)

# 2. Juntar com abundância
combined_data <- SVs_long %>%
  dplyr::left_join(health_data, by = "Sample.id")

# 3. Calcular correlações para cada ASV com as variáveis de saúde
cor_results <- combined_data %>%
  dplyr::group_by(Feature.ID) %>%
  dplyr::summarize(across(
    .cols = c(IL17A, IFNGamma, TNF, IL10, IL6, IL4, IL2, Age,
              Systolic, Diastolic, UREIA, CREATININA, HbA1c, COLESTEROL, LDL,
              HDL, VLDL, TRIGLICERIDES, TGO, TGP, GGT, GLICOSE, INSULINA,
              HOMA, PCR, IMC, W_H_ratio),
    .fns = ~ cor(NormAbundance, .x, use = "complete.obs"),
    .names = "cor_{.col}"
  )) %>%
  dplyr::ungroup()

# 4. Transformar em formato longo
cor_long <- cor_results %>%
  tidyr::pivot_longer(cols = starts_with("cor_"), names_to = "Health_Param", values_to = "Correlation") %>%
  dplyr::mutate(Health_Param = gsub("cor_", "", Health_Param))

# 5. Criar matriz
cor_matrix <- cor_long %>%
  tidyr::pivot_wider(names_from = Health_Param, values_from = Correlation) %>%
  tibble::column_to_rownames("Feature.ID") %>%
  as.matrix()

# 6. Heatmap
color_palette <- colorRampPalette(c("blue", "white", "red"))(50)
breaks <- seq(-0.5, 0.5, length.out = 51)

pheatmap(cor_matrix, 
         clustering_method = "ward.D2",
         clustering_distance_rows = "euclidean",
         clustering_distance_cols = "euclidean",
         main = "Heatmap de Correlação entre ASVs e Parâmetros de Saúde",
         color = color_palette, 
         breaks = breaks,
         border_color = NA)

```


```{r}
library(dplyr)
library(tidyr)

# Função para calcular correlação e p-valor
calc_cor_p <- function(x, y) {
  valid <- complete.cases(x, y)
  if (sum(valid) > 2) {
    res <- suppressWarnings(cor.test(x[valid], y[valid]))
    return(c(correlation = res$estimate, p_value = res$p.value))
  } else {
    return(c(correlation = NA, p_value = NA))
  }
}

# Lista de variáveis de saúde
health_vars <- c("IL17A", "IFNGamma", "TNF", "IL10", "IL6", "IL4", "IL2", "Age",
                 "Systolic", "Diastolic", "UREIA", "CREATININA", "HbA1c",
                 "COLESTEROL", "LDL", "HDL", "VLDL", "TRIGLICERIDES", "TGO", "TGP",
                 "GGT", "GLICOSE", "INSULINA", "HOMA", "PCR", "IMC", "W_H_ratio")

# Criar uma lista vazia para guardar os resultados
cor_list <- list()

# Loop pelas variáveis de saúde
for (var in health_vars) {
  temp <- combined_data %>%
    group_by(Feature.ID) %>%
    summarise(
      correlation = calc_cor_p(NormAbundance, .data[[var]])["correlation"],
      p_value = calc_cor_p(NormAbundance, .data[[var]])["p_value"]
    ) %>%
    ungroup() %>%
    mutate(variable = var)
  
  cor_list[[var]] <- temp
}

# Unir todos os resultados
cor_all <- bind_rows(cor_list)

# Ajustar p-valor com FDR
cor_all <- cor_all %>%
  group_by(variable) %>%
  mutate(p_adj = p.adjust(p_value, method = "fdr")) %>%
  ungroup()

# Marcar significância
cor_all <- cor_all %>%
  mutate(star = case_when(
    p_adj < 0.001 ~ "***",
    p_adj < 0.01 ~ "**",
    p_adj < 0.05 ~ "*",
    TRUE ~ ""
  ))

# Visualizar resultados formatados
head(cor_all)

```



```{r}
# Verificar se `significant_correlations` e `taxonomy` contêm dados relevantes antes da junção
head(significant_correlations)
head(taxonomy)

# Certificar-se de que `Feature.ID` existe em ambos os conjuntos de dados
if("Feature.ID" %in% colnames(significant_correlations) & "Feature.ID" %in% colnames(taxonomy)) {
  # Realizar a junção novamente, assegurando que `Taxon` está sendo trazido corretamente
  significant_correlations_with_taxonomy <- significant_correlations %>%
    left_join(taxonomy, by = "Feature.ID") %>%
    select(Taxon, Health_Param, Correlation, p_value) %>%
    distinct() # Remover duplicatas, se houver
  
  # Conferir se há dados após a junção
  if(nrow(significant_correlations_with_taxonomy) > 0) {
    library(DT)
    
    # Exibir a tabela interativa
    datatable(significant_correlations_with_taxonomy, 
              options = list(pageLength = 10), 
              caption = 'Correlações Significativas entre Taxon e Parâmetros de Saúde')
  } else {
    print("A tabela ainda está vazia após a junção.")
  }
} else {
  print("Verifique se a coluna Feature.ID existe em ambos os datasets.")
}


```


```{r}
install.packages("DT")
library(DT)

# Mostrar a tabela interativa com `DT`
datatable(formatted_table, options = list(pageLength = 10), caption = 'Correlações Significativas entre Taxon e Parâmetros de Saúde')

```

```{r}
library(writexl)

# Salvar a tabela como um arquivo Excel
write_xlsx(significant_correlations_with_taxonomy, "C:/Users/polia/OneDrive/Desktop/EstatisticaR/AgrUrbana/16S_AgriUrbana/Planilhas/significant_correlations_with_taxonomy.xlsx")

```


#========== Clusters =================#

```{r}
metadata__ASVs_Saude_Dieta_NOVA <- merge(metadata__ASVs_Saude_Dieta_NOVA, 
                                         metadados.alpha.all[, c("Sample.id", "Cluster_Hclust")], 
                                         by = "Sample.id", 
                                         all.x = TRUE)


```


#===== Clusters x Saúde =======#

```{r}

# Carregar pacotes necessários
library(ggplot2)
library(dplyr)
library(ggpubr)  # Para adicionar valores de p aos boxplots

# Lista de variáveis contínuas
continuous_vars <- c("COLESTEROL", "LDL", "TRIGLICERIDES", "TyG", "TyG_BMI", "TyG_WC")

# Criar um dataframe para armazenar os resultados
resultados <- data.frame(Variável = character(),
                         Média_Cluster1 = numeric(),
                         Média_Cluster2 = numeric(),
                         P_valor = numeric(),
                         Significância = character(),
                         stringsAsFactors = FALSE)

# Loop para realizar os testes t
for (var in continuous_vars) {
  # Teste t para comparar os clusters
  t_test <- t.test(metadados.alpha.all[[var]] ~ metadados.alpha.all$Cluster_Hclust)

  # Médias por grupo
  medias <- metadados.alpha.all %>%
    group_by(Cluster_Hclust) %>%
    summarise(Media = mean(.data[[var]], na.rm = TRUE)) %>%
    pull(Media)

  # Determinar a significância
  sig <- ifelse(t_test$p.value < 0.001, "***",
                ifelse(t_test$p.value < 0.01, "**",
                       ifelse(t_test$p.value < 0.05, "*", "")))

  # Adicionar os resultados ao dataframe
  resultados <- rbind(resultados, data.frame(
    Variável = var,
    Média_Cluster1 = round(medias[1], 2),
    Média_Cluster2 = round(medias[2], 2),
    P_valor = round(t_test$p.value, 4),  # Arredondar para 4 casas decimais
    Significância = sig
  ))
}

# Exibir os resultados
print(resultados)




# Salvar em CSV
write.csv(resultados, "C:/Users/polia/OneDrive/Desktop/EstatisticaR/AgrUrbana/16S_AgriUrbana/Planilhas_UrbanAgri/resultados_teste_t.csv", row.names = FALSE)




```

```{r}
library(gridExtra)

# Criar uma lista para armazenar os plots
plot_list <- list()

# Gerar os boxplots e armazenar na lista
for (var in continuous_vars) {
  p_val <- t.test(metadados.alpha.all[[var]] ~ metadados.alpha.all$Cluster_Hclust)$p.value
  p_val_text <- paste0("p = ", round(p_val, 4))

  p <- ggplot(metadados.alpha.all, aes(x = as.factor(Cluster_Hclust), y = .data[[var]], fill = as.factor(Cluster_Hclust))) +
    geom_boxplot() +
    labs(title = var, x = "Cluster", y = var) +
    theme_minimal() +
    scale_fill_manual(values = c("#F8766D", "#00BFC4"), name = "Cluster") +
    theme(legend.position = "none") +
    annotate("text", x = 1.5, y = max(metadados.alpha.all[[var]], na.rm = TRUE) * 1.05, 
             label = p_val_text, size = 4, color = "black")

  plot_list[[var]] <- p
}

# Salvar os plots em um único arquivo PNG
png("boxplots_clusters.png", width = 14, height = 10, units = "in", res = 300)
grid.arrange(grobs = plot_list, ncol = 3)  # Ajuste ncol para mudar o layout
dev.off()


```

#=========== Cluster x Diet ===============#
```{r}
metadados_dieta_cluster <- merge(diet_residual, 
                                         metadados.alpha.all[, c("Sample.id", "Cluster_Hclust")], 
                                         by = "Sample.id", 
                                         all.x = TRUE)
```

```{r}
library(dplyr)

# Remover NAs antes de realizar os testes
metadados_dieta_cluster_clean <- metadados_dieta_cluster %>%
  select(Cluster_Hclust, all_of(diet_vars)) %>%
  na.omit()

# Criar uma tabela para armazenar os resultados
results <- data.frame(Variable = character(), p_value = numeric(), Significance = character())

# Loop para testar todas as variáveis e salvar os resultados
for (var in diet_vars) {
  p_val <- t.test(metadados_dieta_cluster_clean[[var]] ~ metadados_dieta_cluster_clean$Cluster_Hclust)$p.value
  signif_label <- ifelse(p_val < 0.001, "***", 
                         ifelse(p_val < 0.01, "**", 
                                ifelse(p_val < 0.05, "*", "")))
  
  results <- rbind(results, data.frame(Variable = var, p_value = round(p_val, 4), Significance = signif_label))
}

# Exibir a tabela com os resultados
print(results)

# Salvar os resultados em um arquivo CSV
write.csv(results, "resultados_dieta_clusters_sem_NA.csv", row.names = FALSE)

# Filtrar apenas variáveis com p < 0.05 para boxplot
significant_vars <- results %>% filter(p_value < 0.05) %>% pull(Variable)

# Criar boxplots apenas para as variáveis significativas
if (length(significant_vars) > 0) {
  library(ggplot2)
  library(gridExtra)

  plot_list <- list()

  for (var in significant_vars) {
    p_val_text <- paste0("p = ", results$p_value[results$Variable == var])
    
    p <- ggplot(metadados_dieta_cluster_clean, aes(x = as.factor(Cluster_Hclust), y = .data[[var]], fill = as.factor(Cluster_Hclust))) +
      geom_boxplot() +
      labs(title = var, x = "Cluster", y = var) +
      theme_minimal() +
      scale_fill_manual(values = c("#F8766D", "#00BFC4"), name = "Cluster") +
      theme(legend.position = "none") +
      annotate("text", x = 1.5, y = max(metadados_dieta_cluster_clean[[var]], na.rm = TRUE) * 1.05, 
               label = p_val_text, size = 5, color = "black")

    plot_list[[var]] <- p
  }

  # Salvar os boxplots juntos em um único PDF
  pdf("boxplots_significativos_dieta_clusters_sem_NA.pdf", width = 10, height = 6)
  for (p in plot_list) {
    print(p)
  }
  dev.off()

  # Salvar como PNG
  png("boxplots_significativos_dieta_clusters_sem_NA.png", width = 10, height = 6, units = "in", res = 300)
  gridExtra::grid.arrange(grobs = plot_list, ncol = 2) 
  dev.off()
} else {
  print("Nenhuma variável apresentou significância estatística (p < 0.05)")
}

```


```{r}
# Criar um novo dataframe apenas com Sample.id e Cluster_Hclust
Cluster <- metadados.alpha.all[, c("Sample.id", "Cluster_Hclust")]

# Verificar se os dados foram extraídos corretamente
head(Cluster)

```


```{r}
SVs_normalized_t <- as.data.frame(t(SVs_normalized), check.names = FALSE)


# Carregar o pacote necessário
library(tibble)

# Garantir que a coluna Sample.id exista em Cluster
if (!"Sample.id" %in% colnames(Cluster)) {
  stop("A coluna 'Sample.id' não está presente em Cluster.")
}

# Converter os rownames para uma coluna chamada Sample.id
SVs_normalized_t <- rownames_to_column(SVs_normalized_t, var = "Sample.id")

# Realizar o merge
merged_data <- merge(SVs_normalized_t, Cluster, by = "Sample.id", all.x = TRUE)

# Exibir as primeiras linhas do resultado
head(merged_data)
```
```{r}
# Remover linhas onde Cluster_Hclust é NA
ASVs_Cluster <- na.omit(merged_data)

# Verificar se ainda há NAs
sum(is.na(ASVs_Cluster$Cluster_Hclust))

# Exibir as primeiras linhas do novo objeto
head(ASVs_Cluster)

```
```{r}

# Criar uma tabela com a presença/ausência de ASVs por cluster
presenca_ASVs <- aggregate(. ~ Cluster_Hclust, data = ASVs_Cluster, function(x) sum(x > 0))

# Separar ASVs exclusivas de cada cluster
ASVs_exclusivas <- apply(presenca_ASVs[,-1], 2, function(x) sum(x > 0))

# Contar ASVs exclusivas por cluster
table(presenca_ASVs$Cluster_Hclust)

View(presenca_ASVs)

```


```{r}
# Criar uma lista para armazenar os top 30 ASVs por cluster
top_30_ASVs <- list()

# Iterar sobre cada cluster para identificar as 30 ASVs mais abundantes
for (cluster in unique(presenca_ASVs$Cluster_Hclust)) {
  
  # Filtrar as ASVs para o cluster específico
  dados_cluster <- presenca_ASVs[presenca_ASVs$Cluster_Hclust == cluster, -c(1, 2)]  # Remove Cluster_Hclust e Sample.id
  
  # Calcular a média de abundância relativa para cada ASV no cluster
  media_ASVs <- colMeans(dados_cluster, na.rm = TRUE)
  
  # Selecionar as 30 ASVs mais abundantes
  top_ASVs <- sort(media_ASVs, decreasing = TRUE)[1:30]
  
  # Armazenar no dicionário/lista
  top_30_ASVs[[paste0("Cluster_", cluster)]] <- names(top_ASVs)
}

# Visualizar as ASVs mais abundantes em cada cluster
print(top_30_ASVs)


```
```{r}
# Criar um dataframe com as ASVs mais abundantes
top_30_taxonomy <- data.frame(
  ASV = unlist(top_30_ASVs),
  Cluster = rep(names(top_30_ASVs), each = 30)  # Criar coluna indicando o cluster de cada ASV
)

# Adicionar a taxonomia correspondente
top_30_taxonomy$Taxon <- taxonomy$Taxon[match(top_30_taxonomy$ASV, taxonomy$Feature.ID)]

# Visualizar o resultado
head(top_30_taxonomy)

```


```{r}
# Criar um dataframe apenas para Cluster 1
top_30_cluster1 <- subset(top_30_taxonomy, Cluster == "Cluster_1")

# Criar um dataframe apenas para Cluster 2
top_30_cluster2 <- subset(top_30_taxonomy, Cluster == "Cluster_2")

# Verificar se a separação foi feita corretamente
head(top_30_cluster1)
head(top_30_cluster2)

```

```{r}
# Quais ASVs aparecem nos dois clusters?
ASVs_comuns <- intersect(top_30_cluster1$ASV, top_30_cluster2$ASV)

# Quais são exclusivas de cada cluster?
ASVs_exclusivas_cluster1 <- setdiff(top_30_cluster1$ASV, top_30_cluster2$ASV)
ASVs_exclusivas_cluster2 <- setdiff(top_30_cluster2$ASV, top_30_cluster1$ASV)

# Exibir resultados
list(
  ASVs_comuns = ASVs_comuns,
  Exclusivas_Cluster1 = ASVs_exclusivas_cluster1,
  Exclusivas_Cluster2 = ASVs_exclusivas_cluster2
)

```


```{r}

# Extrair o nível de família (posição 5) ou gênero (posição 6) da taxonomia
top_30_cluster1$Familia <- sapply(strsplit(top_30_cluster1$Taxon, ";"), function(x) x[5])
top_30_cluster1$Genero <- sapply(strsplit(top_30_cluster1$Taxon, ";"), function(x) x[6])

top_30_cluster2$Familia <- sapply(strsplit(top_30_cluster2$Taxon, ";"), function(x) x[5])
top_30_cluster2$Genero <- sapply(strsplit(top_30_cluster2$Taxon, ";"), function(x) x[6])

# Remover espaços extras
top_30_cluster1$Familia <- trimws(top_30_cluster1$Familia)
top_30_cluster1$Genero <- trimws(top_30_cluster1$Genero)
top_30_cluster2$Familia <- trimws(top_30_cluster2$Familia)
top_30_cluster2$Genero <- trimws(top_30_cluster2$Genero)

# Conferir os primeiros dados
head(top_30_cluster1)
head(top_30_cluster2)


```


```{r}
library(ggplot2)

# Criar um dataframe com a contagem de famílias por cluster
familia_freq <- rbind(
  data.frame(Familia = top_30_cluster1$Familia, Cluster = "Cluster 1"),
  data.frame(Familia = top_30_cluster2$Familia, Cluster = "Cluster 2")
)

# Criar histograma
ggplot(familia_freq, aes(x = Familia, fill = Cluster)) +
  geom_bar(position = "dodge") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Comparação de Famílias Entre Clusters", x = "Família", y = "Frequência", fill = "Cluster")



```


```{r}

# Criar um dataframe com a contagem de gêneros por cluster
genero_freq <- rbind(
  data.frame(Genero = top_30_cluster1$Genero, Cluster = "Cluster 1"),
  data.frame(Genero = top_30_cluster2$Genero, Cluster = "Cluster 2")
)

# Criar histograma
ggplot(genero_freq, aes(x = Genero, fill = Cluster)) +
  geom_bar(position = "dodge") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Comparação de Gêneros Entre Clusters", x = "Gênero", y = "Frequência", fill = "Cluster")


```


```{r}
library(ggplot2)
library(reshape2)

# Contagem de famílias por cluster
familia_freq_cluster1 <- as.data.frame(table(top_30_cluster1$Familia))
familia_freq_cluster2 <- as.data.frame(table(top_30_cluster2$Familia))

# Nomear colunas corretamente
colnames(familia_freq_cluster1) <- c("Familia", "Frequencia")
colnames(familia_freq_cluster2) <- c("Familia", "Frequencia")

# Adicionar a informação de cluster
familia_freq_cluster1$Cluster <- "Cluster 1"
familia_freq_cluster2$Cluster <- "Cluster 2"

# Unir os dados
familia_freq_total <- rbind(familia_freq_cluster1, familia_freq_cluster2)

# Visualizar os dados organizados
head(familia_freq_total)



```


```{r}
ggplot(familia_freq_total, aes(x = Cluster, y = Frequencia, fill = Familia)) +
  geom_bar(stat = "identity", position = "stack") +
  theme_minimal() +
  labs(title = "Distribuição das Famílias nos Clusters",
       x = "Cluster", y = "Frequência",
       fill = "Família") +
  theme(axis.text.x = element_text(size = 12),
        axis.title = element_text(size = 14),
        legend.position = "right")



```


```{r}

library(ggplot2)
library(RColorBrewer)

# Definir uma paleta de cores mais distintas
cores_diferentes <- colorRampPalette(brewer.pal(12, "Paired"))(length(unique(familia_freq_total$Familia)))

# Criar o gráfico ajustado
ggplot(familia_freq_total, aes(x = Cluster, y = Frequencia, fill = Familia)) +
  geom_bar(stat = "identity", position = "stack", width = 0.4) +  # Ajustando a largura da barra
  scale_fill_manual(values = cores_diferentes) +  # Aplicando a paleta de cores
  theme_minimal() +
  labs(title = "Distribuição das Famílias nos Clusters",
       x = "Cluster", y = "Frequência",
       fill = "Família") +
  theme(axis.text.x = element_text(size = 14),
        axis.title = element_text(size = 16),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12),
        legend.key.size = unit(0.8, "cm"))


```


```{r}
library(ggplot2)
library(RColorBrewer)

# Criar contagem de gêneros por cluster
genero_freq_cluster1 <- as.data.frame(table(top_30_cluster1$Genero))
genero_freq_cluster2 <- as.data.frame(table(top_30_cluster2$Genero))

# Nomear colunas corretamente
colnames(genero_freq_cluster1) <- c("Genero", "Frequencia")
colnames(genero_freq_cluster2) <- c("Genero", "Frequencia")

# Adicionar a informação de cluster
genero_freq_cluster1$Cluster <- "Cluster 1"
genero_freq_cluster2$Cluster <- "Cluster 2"

# Unir os dados
genero_freq_total <- rbind(genero_freq_cluster1, genero_freq_cluster2)

# Visualizar os dados organizados
head(genero_freq_total)


```


```{r}
# Definir uma paleta de cores mais distintas
cores_diferentes <- colorRampPalette(brewer.pal(12, "Set3"))(length(unique(genero_freq_total$Genero)))

# Criar o gráfico ajustado
ggplot(genero_freq_total, aes(x = Cluster, y = Frequencia, fill = Genero)) +
  geom_bar(stat = "identity", position = "stack", width = 0.4) +  # Ajustando a largura da barra
  scale_fill_manual(values = cores_diferentes) +  # Aplicando a paleta de cores
  theme_minimal() +
  labs(title = "Distribuição dos Gêneros nos Clusters",
       x = "Cluster", y = "Frequência",
       fill = "Gênero") +
  theme(axis.text.x = element_text(size = 14),
        axis.title = element_text(size = 16),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12),
        legend.key.size = unit(0.8, "cm"))


```


```{r}
# Listar os gêneros presentes em cada cluster
generos_cluster1 <- unique(top_30_cluster1$Genero)
generos_cluster2 <- unique(top_30_cluster2$Genero)

# Gêneros comuns entre os clusters
generos_comuns <- intersect(generos_cluster1, generos_cluster2)

# Gêneros exclusivos de cada cluster
generos_exclusivos_cluster1 <- setdiff(generos_cluster1, generos_cluster2)
generos_exclusivos_cluster2 <- setdiff(generos_cluster2, generos_cluster1)
```

```{r}
# Criar uma lista para a tabela
data <- list(
  "Gêneros Comuns" = generos_comuns,
  "Gêneros Exclusivos Cluster 1" = generos_exclusivos_cluster1,
  "Gêneros Exclusivos Cluster 2" = generos_exclusivos_cluster2
)

# Ajustar o número de linhas para o maior vetor
max_len <- max(length(generos_comuns), length(generos_exclusivos_cluster1), length(generos_exclusivos_cluster2))

# Preencher com NA para manter o formato correto
data <- lapply(data, function(x) {length(x) <- max_len; x})

# Criar o dataframe
tabela_generos <- as.data.frame(data)

# Exibir a tabela
print(tabela_generos)

```

