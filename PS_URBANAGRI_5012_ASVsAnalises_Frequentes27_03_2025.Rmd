---
title: "R Notebook"
output: html_notebook
---

```{r}
# Carregar pacotes necessários
library(tidyverse)


# Instalar microbiomeMarker via Bioconductor
BiocManager::install("microbiomeMarker")

library(microbiomeMarker)

library(qiime2R)
library(phyloseq)
install.packages("xfun")

library(tibble)

```



```{r}
#metadata <- read.csv("C:/Users/polia/OneDrive/Desktop/EstatisticaR/AgrUrbana/16S_AgriUrbana/metadados_raw_V01_local_nascimento2.csv", 
                     sep = ";", 
                     header = TRUE, 
                     stringsAsFactors = FALSE, 
                     fileEncoding = "UTF-8")

metadata <-metadados.raw

# Manter apenas as primeiras 130 linhas
metadata <- metadata[1:130, ]

# Remover a primeira coluna
metadata <- metadata[, -1]


# Remover quaisquer linhas completamente vazias (se necessário)
metadata <- metadata[rowSums(is.na(metadata)) != ncol(metadata), ]



# Exibir as primeiras linhas para verificar se os dados foram importados corretamente
head(metadata)

# Verifique os nomes das colunas para garantir que foram carregados corretamente
colnames(metadata)



SVs<-read_qza("C:/Users/polia/OneDrive/Desktop/EstatisticaR/AgrUrbana/16S_AgriUrbana/table.qza")$data
taxonomy<-read_qza("C:/Users/polia/OneDrive/Desktop/EstatisticaR/AgrUrbana/16S_AgriUrbana/taxonomy_silva.qza")$data
```




```{r}
SVs <- ASV.table.raw

# Calcular o número de voluntários em que cada ASV está presente
asv_presence <- rowSums(SVs > 0)

# Filtrar ASVs presentes em pelo menos 13 voluntários
SVs_filtered <- SVs[asv_presence >= 10, ]


```


```{r}


# Normalizar para porcentagem
SVs_normalized <- apply(SVs_filtered, 2, function(x) x / sum(x) * 100)  # Converte para porcentagem

```


```{r}
# Transformar em data frame para manipulação
SVs_long <- SVs_normalized %>%
  as.data.frame() %>%
  rownames_to_column("Feature.ID") %>%
  gather(-Feature.ID, key = "Sample.id", value = "Abundance")

```


```{r}
# Aplicar transformação logarítmica

SVs_long <- SVs_long %>%
  mutate(NormAbundance = log10(Abundance + 0.01))  # Adiciona 0.01 para evitar log(0)

# Exportar para uma planilha
write.csv(SVs_long, "SVs_normalized_log_transformed.csv", row.names = FALSE)



```


```{r}
library(ggplot2)
library(pheatmap)

# Converter de volta para formato largo para o heatmap
SVs_matrix <- SVs_long %>%
  select(Feature.ID, Sample.id, NormAbundance) %>%
  spread(key = Sample.id, value = NormAbundance, fill = 0) %>%
  column_to_rownames("Feature.ID")



# Definir a paleta de cores com branco no centro
color_palette <- colorRampPalette(c("blue", "white", "red"))(50)

# Gerar o heatmap com o ponto zero centralizado na cor branca
pheatmap(SVs_matrix, 
         clustering_method = "ward.D2",  # Método de clusterização
         clustering_distance_rows = "euclidean",  # Distância para ASVs
         clustering_distance_cols = "euclidean",  # Distância para amostras
         scale = "row",  # Escala por linha para melhor visualização
         main = "Heatmap de Abundância Normalizada e Log-transformada das ASVs",
         color = color_palette)

```

```{r}
library(pheatmap)

# Selecionar as 50 ASVs mais abundantes
top_ASVs <- rowSums(SVs_matrix) %>% sort(decreasing = TRUE) %>% head(50) %>% names()
SVs_matrix_top <- SVs_matrix[top_ASVs, ]

# Criar a paleta de cores com branco centralizado
color_palette <- colorRampPalette(c("blue", "white", "red"))(100)

# Gerar o heatmap com as top 50 ASVs
pheatmap(SVs_matrix_top, 
         clustering_method = "ward.D2",
         clustering_distance_rows = "euclidean",
         clustering_distance_cols = "euclidean",
         scale = "row",
         main = "Heatmap das 50 ASVs Mais Abundantes (Normalizado e Log-transformado)",
         color = color_palette)


```



```{r}
library(dplyr)





# Remover as colunas indesejadas do metadata
metadata_filtered <- metadados.all %>%
  select(-c("Gravida", "Menopausa", "Raca", "Gravida", "Weight", "Height",  "Hip","WHR"                ))

str(metadata_filtered)


# Juntar ASVs_long com metadata filtrado
# Assumindo que a coluna de junção seja "Sample.id" em ASVs_long e "SampleID" em metadata_filtered
metadata_ASVs <- SVs_long %>%
  inner_join(metadata_filtered, by = c("Sample.id" = "Sample.id"))

```

```{r}
library(dplyr)

# Juntar o objeto taxonomy ao metadata_ASVs usando a coluna Feature.ID
metadata_ASVs <- metadata_ASVs %>%
  left_join(taxonomy %>% select(Feature.ID, Taxon, Confidence), by = "Feature.ID")

# Reorganizar para que Taxon seja a segunda coluna e Confidence a terceira
metadata_ASVs <- metadata_ASVs %>%
  select(Feature.ID, Taxon, Confidence, everything())

# Visualizar o resultado
metadata_ASVs

```

```{r}
# Reorganizar para que Sample.id seja a primeira coluna
metadata_ASVs <- metadata_ASVs %>%
  select(Sample.id, everything())

# Visualizar o resultado
glimpse(metadata_ASVs)

```

```{r}
library(dplyr)
library(ggplot2)

# Filtrar apenas colunas numéricas de metadata e manter Sample.id
numeric_metadata <- metadata %>%
  select(Sample.id, where(is.numeric))

# Preparar dados para o heatmap usando SVs_long e combinando com colunas numéricas de metadata
heatmap_data <- SVs_long %>%
  left_join(numeric_metadata, by = "Sample.id") %>%
  left_join(taxonomy, by = "Feature.ID") %>%
  mutate(Feature = paste(Feature.ID, Taxon)) %>%
  mutate(Feature = gsub("[kpcofgs]__", "", Feature))  # Remover prefixos na taxonomia

# Plotar o heatmap
ggplot(heatmap_data, aes(x = Sample.id, y = Feature, fill = NormAbundance)) +
  geom_tile() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_viridis_c(name = "NormAbundance") +
  labs(title = "Heatmap de Abundância Normalizada das ASVs", x = "Sample ID", y = "ASV (Feature.ID e Taxonomia)")

# Salvar o gráfico como PDF
ggsave("heatmap.pdf", height = 4, width = 11, device = "pdf")


```

```{r}
library(dplyr)
library(ggplot2)

# Filtrar apenas colunas numéricas de metadata e manter Sample.id
numeric_metadata <- metadados.all %>%
  select(Sample.id, where(is.numeric))

# Preparar dados para o heatmap usando SVs_long e combinando com colunas numéricas de metadata
heatmap_data <- SVs_long %>%
  left_join(numeric_metadata, by = "Sample.id") %>%
  left_join(taxonomy, by = "Feature.ID") 

# Plotar o heatmap
ggplot(heatmap_data, aes(x = Sample.id, y = Feature.ID, fill = NormAbundance)) +
  geom_tile() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_viridis_c(name = "NormAbundance") +
  labs(title = "Heatmap de Abundância Normalizada das ASVs", x = "Sample ID", y = "Feature.ID")

# Salvar o gráfico como PDF
ggsave("heatmap_larger.pdf", height = 10, width = 20, device = "pdf")


```

```{r}



library(dplyr)
library(tidyr)
library(pheatmap)
library(tibble)

# 1. Selecionar apenas colunas relevantes de saúde
# Corrigido
health_data <- metadata_ASVs %>%
  select(Sample.id, IL17A, IFNGamma, TNF, IL10, IL6, IL4, IL2, Age,
                Systolic, Diastolic, UREIA, CREATININA, HbA1c, COLESTEROL, LDL,
                HDL, VLDL, TRIGLICERIDES, TGO, TGP, GGT, GLICOSE, INSULINA, HOMA.IR, 
                PCR, BMI, TyG, VAI, QUICKI, METS_IR, W.H) %>%
  distinct(Sample.id, .keep_all = TRUE)


# 2. Juntar com abundância
combined_data <- SVs_long %>%
 left_join(health_data, by = "Sample.id")

# 3. Calcular correlações para cada ASV com as variáveis de saúde
cor_results <- combined_data %>%
 group_by(Feature.ID) %>%
  summarize(across(
    .cols = c(IL17A, IFNGamma, TNF, IL10, IL6, IL4, IL2, Age,
                Systolic, Diastolic, UREIA, CREATININA, HbA1c, COLESTEROL, LDL,
                HDL, VLDL, TRIGLICERIDES, TGO, TGP, GGT, GLICOSE, INSULINA, HOMA.IR, 
                PCR, BMI, TyG, VAI, QUICKI, METS_IR, W.H),
    .fns = ~ cor(NormAbundance, .x, use = "complete.obs"),
    .names = "cor_{.col}"
  )) %>%
 ungroup()

# 4. Transformar em formato longo
cor_long <- cor_results %>%
  pivot_longer(cols = starts_with("cor_"), names_to = "Health_Param", values_to = "Correlation") %>%
 mutate(Health_Param = gsub("cor_", "", Health_Param))

# 5. Criar matriz
cor_matrix <- cor_long %>%
pivot_wider(names_from = Health_Param, values_from = Correlation) %>%
column_to_rownames("Feature.ID") %>%
  as.matrix()

# 6. Heatmap
color_palette <- colorRampPalette(c("blue", "white", "red"))(50)
breaks <- seq(-0.5, 0.5, length.out = 51)

pheatmap(cor_matrix, 
         clustering_method = "ward.D2",
         clustering_distance_rows = "euclidean",
         clustering_distance_cols = "euclidean",
         main = "Heatmap de Correlação entre ASVs e Parâmetros de Saúde",
         color = color_palette, 
         breaks = breaks,
         border_color = NA)

```


```{r}
library(dplyr)
library(tidyr)

# Função para calcular correlação e p-valor
calc_cor_p <- function(x, y) {
  valid <- complete.cases(x, y)
  if (sum(valid) > 2) {
    res <- suppressWarnings(cor.test(x[valid], y[valid]))
    return(c(correlation = as.numeric(res$estimate), p_value = res$p.value))
  } else {
    return(c(correlation = NA_real_, p_value = NA_real_))
  }
}


# Lista de variáveis de saúde
health_vars <- c("IL17A", "IFNGamma", "TNF", "IL10", "IL6", "IL4", "IL2", "Age",
                "Systolic", "Diastolic", "UREIA", "CREATININA", "HbA1c", "COLESTEROL", "LDL",
                "HDL", "VLDL", "TRIGLICERIDES", "TGO", "TGP", "GGT", "GLICOSE", "INSULINA", "HOMA.IR", 
                "PCR", "BMI", "TyG", "VAI", "QUICKI", "METS_IR", "W.H")

# Criar uma lista vazia para guardar os resultados
cor_list <- list()

# Loop pelas variáveis de saúde
for (var in health_vars) {
  
  temp <- combined_data %>%
    group_by(Feature.ID) %>%
    summarise(
      correlation = calc_cor_p(NormAbundance, .data[[var]])["correlation"],
      p_value = calc_cor_p(NormAbundance, .data[[var]])["p_value"]
    ) %>%
    ungroup() %>%
    mutate(variable = var) %>%
    mutate(
      correlation = as.numeric(correlation),
      p_value = as.numeric(p_value)
    )
  
  # Armazenar na lista
  cor_list[[var]] <- temp
}


# Unir todos os resultados
cor_all <- bind_rows(cor_list)

# Ajustar p-valor com FDR
cor_all <- cor_all %>%
  group_by(variable) %>%
  mutate(p_adj = p.adjust(p_value, method = "fdr")) %>%
  ungroup()

# Marcar significância
cor_all <- cor_all %>%
  mutate(star = case_when(
    p_adj < 0.001 ~ "***",
    p_adj < 0.01 ~ "**",
    p_adj < 0.05 ~ "*",
    TRUE ~ ""
  ))

# Visualizar resultados formatados
head(cor_all)

```


```{r}
cor_signif <- cor_all %>%
  filter(p_adj < 0.05)

cor_all %>%
  filter(p_adj < 0.05) %>%
  arrange(desc(abs(correlation)))


```

```{r}
library(pheatmap)
library(dplyr)
library(tidyr)
library(tibble)



# 1. Selecionar apenas ASVs com pelo menos uma correlação significativa (FDR < 0.05)
asvs_signif <- cor_all %>%
  filter(p_adj < 0.05) %>%
  pull(Feature.ID) %>%
  unique()

# 2. Criar matriz de correlação apenas com ASVs significativas
cor_matrix <- cor_all %>%
  filter(Feature.ID %in% asvs_signif) %>%
  select(Feature.ID, variable, correlation) %>%
  pivot_wider(names_from = variable, values_from = correlation) %>%
  column_to_rownames("Feature.ID") %>%
  as.matrix()

# 3. Criar matriz de asteriscos para significância (p_adj)
star_matrix <- cor_all %>%
  filter(Feature.ID %in% asvs_signif) %>%
  select(Feature.ID, variable, star) %>%
  pivot_wider(names_from = variable, values_from = star) %>%
  column_to_rownames("Feature.ID") %>%
  as.matrix()

# 4. Paleta de cores e quebras
color_palette <- colorRampPalette(c("blue", "white", "red"))(100)
breaks <- seq(-0.5, 0.5, length.out = 101)

# 5. Gerar o heatmap com significância destacada
pheatmap(cor_matrix,
         display_numbers = star_matrix,
         clustering_method = "ward.D2",
         clustering_distance_rows = "euclidean",
         clustering_distance_cols = "euclidean",
         color = color_palette,
         breaks = breaks,
         main = "Correlação entre ASVs e Parâmetros de Saúde\n(* FDR < 0.05)",
         fontsize_row = 6,
         fontsize_col = 9,
         fontsize_number = 10,
         border_color = NA)


```
```{r}
# Filtrar apenas ASVs com significância
asvs_signif_df <- cor_all %>%
  filter(p_adj < 0.05) %>%
  distinct(Feature.ID)

# Juntar com a tabela de taxonomia
asvs_tax_signif <- asvs_signif_df %>%
  left_join(taxonomy, by = "Feature.ID")

# Visualizar
head(asvs_tax_signif)

```
```{r}
library(tidyr)

asvs_tax_signif <- asvs_tax_signif %>%
  separate(Taxon, into = c("Domain", "Phylum", "Class", "Order", "Family", "Genus", "Species"),
           sep = ";", fill = "right", remove = FALSE, extra = "drop") %>%
  mutate(across(Domain:Species, ~ gsub("^[a-z]__*", "", .)))  # Remove prefixos tipo "g__"

```

```{r}
# Garantir que os Feature.IDs do heatmap estão no objeto com taxonomia
tax_annot <- taxonomy %>%
  filter(Feature.ID %in% rownames(cor_matrix)) %>%
  separate(Taxon, into = c("Domain", "Phylum", "Class", "Order", "Family", "Genus", "Species"),
           sep = ";", fill = "right", extra = "drop", remove = FALSE) %>%
  mutate(across(Domain:Species, ~ gsub("^[a-z]__*", "", .))) %>%
  select(Feature.ID, Phylum, Family, Genus)  # escolha os níveis que quer mostrar

# Criar data frame com os Feature.IDs como rownames
annotation_row <- tax_annot %>%
  column_to_rownames("Feature.ID")  # Importante: rownames devem ser iguais ao cor_matrix

pheatmap(cor_matrix,
         display_numbers = star_matrix,
         clustering_method = "ward.D2",
         clustering_distance_rows = "euclidean",
         clustering_distance_cols = "euclidean",
         color = color_palette,
         breaks = breaks,
         main = "Correlação entre ASVs e Parâmetros de Saúde\n(* FDR < 0.05)",
         fontsize_row = 6,
         fontsize_col = 9,
         fontsize_number = 10,
         border_color = NA,
         annotation_row = annotation_row)

```
#====================================#
    Dieta
#====================================#

```{r}

library(dplyr)
library(tidyr)

# 1. Vetor com os nomes das variáveis de dieta
diet_vars <- c(
  "carboidrato_total_g", "proteina_g", "lipidios_g", "fibra_alimentar_g",
  "colesterol_mg", "acidos_graxos_saturados_g", "acidos_graxos_monoinsaturados_g",
  "acidos_graxos_poliinsaturados_g", "acidos_graxos_trans_g",
  "calcio_mg", "ferro_mg", "sodio_mg", "magnesio_mg", "fosforo_mg",
  "potassio_mg", "manganes_mg", "zinco_mg", "cobre_mg", "selenio_mcg",
  "vitamina_A_RAE_mcg", "vitamina_D_mcg", "vitamina_E_mg", "tiamina_mg",
  "riboflavina_mg", "niacina_mg", "vitamina_B6_mg", "vitamina_B12_mcg",
  "vitamina_C_mg", "equivalente_de_folato_mcg", "sal_de_adicao_g",
  "acucar_de_adicao_g", "energia2_kcal", "BHEI_R_Score_Total",
  "ConsumoGrupo_NOVA_group_1", "ConsumoGrupo_NOVA_group_2", "ConsumoGrupo_NOVA_group_3",
  "Percentual_NOVA_group_1", "Percentual_NOVA_group_2", "Percentual_NOVA_group_3"
)

```

```{r}


# 2. Função para correlação + p-valor
calc_cor_p <- function(x, y) {
  valid <- complete.cases(x, y)
  if (sum(valid) > 2) {
    res <- suppressWarnings(cor.test(x[valid], y[valid]))
    return(c(correlation = as.numeric(res$estimate), p_value = res$p.value))
  } else {
    return(c(correlation = NA_real_, p_value = NA_real_))
  }
}

# 3. Criar lista para armazenar os resultados por variável
cor_list_diet <- list()

# 4. Loop pelas variáveis de dieta
for (var in diet_vars) {
  temp <- metadados.all %>%
   select(Sample.id, !!sym(var)) %>%
    left_join(SVs_long, by = "Sample.id") %>%
    group_by(Feature.ID) %>%
    summarise(
      correlation = calc_cor_p(Abundancia, .data[[var]])["correlation"],
      p_value     = calc_cor_p(Abundancia, .data[[var]])["p_value"]
    ) %>%
    ungroup() %>%
    mutate(variable = var)

  cor_list_diet[[var]] <- temp
}

# 5. Unir todos os resultados
cor_all_diet <- bind_rows(cor_list_diet)

# 6. Corrigir p-valor (FDR) e marcar significância
cor_all_diet <- cor_all_diet %>%
  group_by(variable) %>%
  mutate(p_adj = p.adjust(p_value, method = "fdr")) %>%
  ungroup() %>%
  mutate(star = case_when(
    p_adj < 0.001 ~ "***",
    p_adj < 0.01  ~ "**",
    p_adj < 0.05  ~ "*",
    TRUE ~ ""
  ))

# 7. Visualizar resultados ordenados
cor_all_diet %>%
  filter(p_adj < 0.05) %>%
  arrange(p_adj)
```

```{r}
library(pheatmap)
library(tidyr)
library(dplyr)
library(tibble)

# 1. Filtrar ASVs com pelo menos uma correlação significativa com variáveis de dieta
asvs_signif_diet <- cor_all_diet %>%
  filter(p_adj < 0.05) %>%
  pull(Feature.ID) %>%
  unique()

# 2. Matriz de correlações
cor_matrix_diet <- cor_all_diet %>%
  filter(Feature.ID %in% asvs_signif_diet) %>%
  select(Feature.ID, variable, correlation) %>%
  pivot_wider(names_from = variable, values_from = correlation) %>%
  column_to_rownames("Feature.ID") %>%
  as.matrix()

# 3. Matriz de significância (*)
star_matrix_diet <- cor_all_diet %>%
  filter(Feature.ID %in% asvs_signif_diet) %>%
  select(Feature.ID, variable, star) %>%
  pivot_wider(names_from = variable, values_from = star) %>%
  column_to_rownames("Feature.ID") %>%
  as.matrix()

# 4. Anotação taxonômica
annotation_row_diet <- taxonomy %>%
  filter(Feature.ID %in% rownames(cor_matrix_diet)) %>%
  separate(Taxon, into = c("Domain", "Phylum", "Class", "Order", "Family", "Genus", "Species"),
           sep = ";", fill = "right", extra = "drop") %>%
  mutate(across(Domain:Species, ~ gsub("^[a-z]__*", "", .))) %>%
  select(Feature.ID, Phylum, Family, Genus) %>%
  column_to_rownames("Feature.ID")

# 5. Paleta de cores para anotação
library(RColorBrewer)

ann_colors_diet <- list(
  Phylum = setNames(brewer.pal(length(unique(annotation_row_diet$Phylum)), "Set3"),
                    unique(annotation_row_diet$Phylum)),
  Family = setNames(brewer.pal(length(unique(annotation_row_diet$Family)), "Paired"),
                    unique(annotation_row_diet$Family)),
  Genus = setNames(brewer.pal(length(unique(annotation_row_diet$Genus)), "Dark2"),
                   unique(annotation_row_diet$Genus))
)

# 6. Paleta e breaks para correlação
color_palette <- colorRampPalette(c("blue", "white", "red"))(100)
breaks <- seq(-0.5, 0.5, length.out = 101)

# 7. Gerar heatmap
pheatmap(cor_matrix_diet,
         display_numbers = star_matrix_diet,
         annotation_row = annotation_row_diet,
         #annotation_colors = ann_colors_diet,
         clustering_method = "ward.D2",
         clustering_distance_rows = "euclidean",
         clustering_distance_cols = "euclidean",
         color = color_palette,
         breaks = breaks,
         main = "Correlação entre ASVs e Variáveis da Dieta\n(* FDR < 0.05)",
         fontsize_row = 6,
         fontsize_col = 9,
         fontsize_number = 10,
         border_color = NA)

```


```{r}
# Preparar nomes taxonômicos amigáveis para as ASVs
taxonomy_named <- taxonomy %>%
  separate(Taxon, into = c("Domain", "Phylum", "Class", "Order", "Family", "Genus", "Species"),
           sep = ";", fill = "right", extra = "drop") %>%
  mutate(across(Domain:Species, ~ gsub("^[a-z]__*", "", .))) %>%
  mutate(Taxon_Label = paste(Phylum, Family, Genus, sep = " | ")) %>%
  select(Feature.ID, Taxon_Label)

```



```{r}
# Preparar dados com nome taxonômico
cor_all_health_named <- cor_all %>%
  left_join(taxonomy_named, by = "Feature.ID") %>%
  filter(!is.na(Taxon_Label))

# Selecionar ASVs significativas
taxa_signif_health <- cor_all_health_named %>%
  filter(p_adj < 0.05) %>%
  pull(Taxon_Label) %>%
  unique()

# Matriz de correlação
cor_matrix_health <- cor_all_health_named %>%
  filter(Taxon_Label %in% taxa_signif_health) %>%
  select(Taxon_Label, variable, correlation) %>%
  pivot_wider(names_from = variable, values_from = correlation, values_fn = mean) %>%
  column_to_rownames("Taxon_Label") %>%
  as.matrix()


# Matriz de asteriscos
star_matrix_health <- cor_all_health_named %>%
  filter(Taxon_Label %in% taxa_signif_health) %>%
  select(Taxon_Label, variable, star) %>%
  pivot_wider(names_from = variable, values_from = star, values_fn = ~ first(na.omit(.))) %>%
  column_to_rownames("Taxon_Label") %>%
  as.matrix()


# Heatmap
pheatmap(cor_matrix_health,
         display_numbers = star_matrix_health,
         clustering_method = "ward.D2",
         clustering_distance_rows = "euclidean",
         clustering_distance_cols = "euclidean",
         color = colorRampPalette(c("blue", "white", "red"))(100),
         breaks = seq(-0.5, 0.5, length.out = 101),
         main = "Correlação entre Taxa e Parâmetros de Saúde\n(* FDR < 0.05)",
         fontsize_row = 7,
         fontsize_col = 9,
         fontsize_number = 10,
         border_color = NA)

```

```{r}
# Substituir IDs por taxonomia
cor_all_diet_named <- cor_all_diet %>%
  left_join(taxonomy_named, by = "Feature.ID") %>%
  filter(!is.na(Taxon_Label))

# Selecionar apenas taxas com pelo menos uma correlação significativa
taxa_signif_diet <- cor_all_diet_named %>%
  filter(p_adj < 0.05) %>%
  pull(Taxon_Label) %>%
  unique()

# Matriz de correlação (média para duplicatas)
cor_matrix_diet <- cor_all_diet_named %>%
  filter(Taxon_Label %in% taxa_signif_diet) %>%
  select(Taxon_Label, variable, correlation) %>%
  pivot_wider(names_from = variable, values_from = correlation, values_fn = mean) %>%
  column_to_rownames("Taxon_Label") %>%
  as.matrix()

# Matriz de asteriscos (pegar o primeiro não nulo)
star_matrix_diet <- cor_all_diet_named %>%
  filter(Taxon_Label %in% taxa_signif_diet) %>%
  select(Taxon_Label, variable, star) %>%
  pivot_wider(names_from = variable, values_from = star, values_fn = ~ first(na.omit(.))) %>%
  column_to_rownames("Taxon_Label") %>%
  as.matrix()

# Gerar o heatmap
pheatmap(cor_matrix_diet,
         display_numbers = star_matrix_diet,
         clustering_method = "ward.D2",
         clustering_distance_rows = "euclidean",
         clustering_distance_cols = "euclidean",
         color = colorRampPalette(c("blue", "white", "red"))(100),
         breaks = seq(-0.5, 0.5, length.out = 101),
         main = "Correlação entre Taxa e Variáveis da Dieta\n(* FDR < 0.05)",
         fontsize_row = 7,
         fontsize_col = 9,
         fontsize_number = 10,
         border_color = NA)

```


#============================================#
          Core Microbiota
#============================================#

```{r}
#Encontrar quais ASVs (linhas da matriz) estão presentes em pelo menos X% das amostras de um determinado grupo — esse conjunto é chamado de "core microbiota" para aquele grupo.
# Função para calcular core microbiota por grupo

get_core_microbiota <- function(SV_matrix, group_vector, group_name, threshold = 0.5) {
  
  #threshold de 0.5 = 50% das amostras
  
  # Subset da matriz de ASVs por grupo
  group_samples <- colnames(SV_matrix)[group_vector == group_name]
  SV_group <- SV_matrix[, group_samples]
  
  # Calcular a presença relativa (em % das amostras)
  presença <- rowSums(SV_group > 0) / length(group_samples)
  
  # Selecionar ASVs com presença acima do limiar
  core_asvs <- presença[presença >= threshold]
  
  return(core_asvs)
}

```

```{r}
# Vetor do grupo
grupo_vai <- metadados_filtrado$VAI_group




```


```{r}
# 1. Pegar os IDs em comum entre metadados e matriz
ids_comuns <- intersect(colnames(SVs_filtrado), metadados_filtrado$Sample.id)

# 2. Filtrar e reordenar ambos para alinhar
SVs_filtrado <- SVs_filtrado[, ids_comuns]
metadados_filtrado <- metadados_filtrado[match(ids_comuns, metadados_filtrado$Sample.id), ]

# 3. Confirmar se as posições batem
stopifnot(all(colnames(SVs_filtrado) == metadados_filtrado$Sample.id))

# 4. Extrair os grupos
grupo_vai <- metadados_filtrado$VAI_group

# 5. Rodar core microbiota
core_low  <- get_core_microbiota(SVs_filtrado, grupo_vai, group_name = "Low", threshold = 0.5)
core_high <- get_core_microbiota(SVs_filtrado, grupo_vai, group_name = "High", threshold = 0.5)

```

```{r}
# Garantir que os IDs de SVs estejam nas linhas
SVs_t <- as.data.frame(t(SVs_filtrado))

# Adicionar coluna com IDs
SVs_t$Sample.id <- rownames(SVs_t)

# Juntar com metadados
SVs_meta <- merge(SVs_t, metadados.saude.alpha[, c("Sample.id", "VAI_group", "TyG_group")], by = "Sample.id")

# Remover NAs
SVs_meta <- SVs_meta %>% filter(!is.na(VAI_group) & !is.na(TyG_group))

```


```{r}
# Separar grupos
SVs_vai <- SVs_meta[, -1]  # Remove Sample.id
grupo_vai <- SVs_meta$VAI_group

# Teste de Mann-Whitney para cada ASV
pvals_vai <- apply(SVs_vai[, -c(ncol(SVs_vai)-1, ncol(SVs_vai))], 2, function(x) {
  wilcox.test(x ~ grupo_vai)$p.value
})

# Calcular log2FC
log2FC_vai <- apply(SVs_vai[, -c(ncol(SVs_vai)-1, ncol(SVs_vai))], 2, function(x) {
  log2(mean(x[grupo_vai == "High"] + 1) / mean(x[grupo_vai == "Low"] + 1))
})

# Criar dataframe de resultados
df_vai <- data.frame(ASV = names(pvals_vai),
                     pvalue = pvals_vai,
                     log2FC = log2FC_vai,
                     FDR = p.adjust(pvals_vai, method = "fdr"))

```

```{r}

library(dplyr)


library(ggplot2)

df_vai$significant <- ifelse(df_vai$FDR < 0.05 & abs(df_vai$log2FC) > 1, "Yes", "No")

df_vai_filtrado <- df_vai %>%
  filter(!is.na(log2FC), !is.na(FDR), is.finite(log2FC), is.finite(FDR))

# Agora, plote o gráfico
ggplot(df_vai_filtrado, aes(x = log2FC, y = -log10(FDR), color = significant)) +
  geom_point() +
  geom_hline(yintercept = -log10(0.05), linetype = "dashed") +
  geom_vline(xintercept = c(-1, 1), linetype = "dashed") +
  scale_color_manual(values = c("gray", "red")) +
  labs(title = "Volcano Plot - VAI (ASVs)", x = "log2 Fold Change", y = "-log10(FDR)") +
  theme_minimal()




```

```{r}
# Marcar como significativo com base no p-valor cru
df_vai$pval_signif <- ifelse(!is.na(df_vai$pvalue) & df_vai$pvalue < 0.05 & abs(df_vai$log2FC) > 1, "Yes", "No")

```

```{r}
library(ggplot2)

ggplot(df_vai, aes(x = log2FC, y = -log10(pvalue), color = pval_signif)) +
  geom_point() +
  geom_hline(yintercept = -log10(0.05), linetype = "dashed") +
  geom_vline(xintercept = c(-1, 1), linetype = "dashed") +
  scale_color_manual(values = c("No" = "gray", "Yes" = "red")) +
  labs(
    title = "Volcano Plot - VAI (ASVs) usando p-valor",
    x = "log2 Fold Change",
    y = "-log10(p-value)"
  ) +
  theme_minimal()

#Esse volcano plot com p-valor cru mostra que algumas ASVs estão significativamente diferentes entre os grupos de VAI, com base nos critérios:

# p-valor < 0.05

# |log2FC| > 1 (ou seja, pelo menos 2x de diferença na média da abundância relativa entre os grupos)

# Essas ASVs estão destacadas em vermelho no gráfico.

```

```{r}
asvs_signif_vai <- df_vai %>%
  filter(pvalue < 0.05, abs(log2FC) > 1) %>%
  arrange(pvalue)

# Visualizar
View(asvs_signif_vai)

```

```{r}
# Supondo que o objeto com a taxonomia se chame 'taxonomy'
asvs_signif_vai_tax <- left_join(asvs_signif_vai, taxonomy, by = c("ASV" = "Feature.ID"))

```

```{r}
library(ggrepel)

# Filtrar significativas com p < 0.05 e |log2FC| > 1
df_vai_tax <- df_vai %>%
  filter(pvalue < 0.05, abs(log2FC) > 1) %>%
  left_join(taxonomy, by = c("ASV" = "Feature.ID")) %>%
  mutate(label = stringr::str_extract(Taxon, "g__[^;]*"))  # extrai o gênero

# Volcano plot com rótulos
ggplot(df_vai, aes(x = log2FC, y = -log10(pvalue))) +
  geom_point(aes(color = pval_signif)) +
  geom_text_repel(data = df_vai_tax, aes(label = label), size = 3, max.overlaps = 10) +
  geom_hline(yintercept = -log10(0.05), linetype = "dashed") +
  geom_vline(xintercept = c(-1, 1), linetype = "dashed") +
  scale_color_manual(values = c("gray", "red")) +
  labs(title = "Volcano Plot - VAI (ASVs) with Taxonomy",
       x = "log2 Fold Change", y = "-log10(p-valor)") +
  theme_minimal()

```

```{r}


library(dplyr)
library(ggplot2)
library(ggpubr)
library(stringr)

# 1. Identificar ASVs significativas no volcano
asvs_signif <- df_vai %>%
  filter(pvalue < 0.05, abs(log2FC) > 1) %>%
  pull(ASV)

# 2. Calcular abundância relativa por amostra
SVs_rel <- sweep(SVs_filtrado, 2, colSums(SVs_filtrado), FUN = "/")

# 3. Transpor e adicionar Sample.id
SVs_long <- as.data.frame(t(SVs_rel))
SVs_long$Sample.id <- rownames(SVs_long)

# 4. Unir com metadados (grupo VAI)
dados_plot <- SVs_long %>%
  left_join(metadados.saude.alpha[, c("Sample.id", "VAI_group")], by = "Sample.id") %>%
  filter(!is.na(VAI_group))

# 5. Pivotar para formato longo
dados_long <- dados_plot %>%
  tidyr::pivot_longer(-c(Sample.id, VAI_group), names_to = "ASV", values_to = "Abundancia")

# 6. Filtrar apenas as ASVs significativas
dados_signif <- dados_long %>% filter(ASV %in% asvs_signif)

# 7. Juntar com a taxonomia e extrair o gênero
dados_signif <- dados_signif %>%
  left_join(taxonomy[, c("Feature.ID", "Taxon")], by = c("ASV" = "Feature.ID")) %>%
  mutate(Genus = str_extract(Taxon, "g__[^;]+"),
         Genus = gsub("g__", "", Genus),
         Genus = ifelse(Genus == "" | is.na(Genus), "Unclassified", Genus))

# 8. Agregar por gênero
dados_genus <- dados_signif %>%
  group_by(Sample.id, VAI_group, Genus) %>%
  summarise(Abundancia = sum(Abundancia), .groups = "drop")

# 9. Gerar boxplot apenas com gêneros das ASVs significantes
ggplot(dados_genus, aes(x = VAI_group, y = Abundancia, fill = VAI_group)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.2, alpha = 0.4) +
  facet_wrap(~ Genus, scales = "free_y") +
  stat_compare_means(method = "wilcox.test", label = "p.signif", size = 4) +
  labs(title = "Relative Abundance of Significant Genera (Volcano) by Visceral Adiposity Index (VAI) Group",
       y = "Relative Abundance", x = "VAI group") +
  scale_fill_manual(values = c("Low" = "#F9A03F", "High" = "#59C3C3")) +
  theme_minimal() +
  theme(legend.position = "none",
        strip.text = element_text(size = 10),
        plot.title = element_text(hjust = 0.5))

```



```{r}
library(ggplot2)
library(dplyr)


# Se você ainda não tiver, agrupe os dados por Genus e VAI_group
dados_agrupados <- dados_genus %>%
  group_by(Genus, VAI_group) %>%
  summarise(Abundancia_media = mean(Abundancia, na.rm = TRUE)) %>%
  ungroup()

# Ordena os gêneros por abundância média no grupo Low
generos_ordenados <- dados_agrupados %>%
  filter(VAI_group == "Low") %>%
  arrange(desc(Abundancia_media)) %>%
  pull(Genus)

# Converte Genus em fator com a ordem desejada
dados_agrupados$Genus <- factor(dados_agrupados$Genus, levels = generos_ordenados)

# Gráfico
ggplot(dados_agrupados, aes(x = Genus, y = Abundancia_media, fill = VAI_group)) +
  geom_col(position = "dodge") + 
  labs(title = "Relative Abundance of Significant Genera by Visceral Adiposity Index (VAI) Group",
       x = NULL, y = "Abundância Relativa", fill = "Grupo VAI") +
  scale_fill_manual(values = c("Low" = "#fdbf11", "High" = "#e66101")) +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(forcats)

# Garante que Feature.ID está como coluna
df_vai <- df_vai %>%
  tibble::rownames_to_column("Feature.ID")


# 1. Selecionar ASVs significativas pelo p-valor
asvs_significativas <- df_vai %>%
  filter(pval_signif == "Yes") %>%
  pull(Feature.ID)

# 2. Filtrar matriz com ASVs significantes
SVs_sig <- SVs_filtrado[asvs_significativas, ]

# 3. Calcular abundância relativa por amostra
SVs_rel <- sweep(SVs_sig, 2, colSums(SVs_sig), FUN = "/") %>% as.data.frame()

# 4. Reorganizar para formato longo
SVs_long <- SVs_rel %>%
  tibble::rownames_to_column("Feature.ID") %>%
  pivot_longer(-Feature.ID, names_to = "Sample.id", values_to = "Abundancia")

# 5. Adicionar taxonomia e grupo VAI
SVs_long <- SVs_long %>%
  left_join(taxonomy, by = "Feature.ID") %>%
  left_join(metadados.saude.alpha[, c("Sample.id", "VAI_group")], by = "Sample.id") %>%
  mutate(Genus = stringr::str_extract(Taxon, "g__[^;]*")) %>%
  mutate(Genus = gsub("g__", "", Genus))

# 6. Calcular média por grupo
abund_por_grupo <- SVs_long %>%
  group_by(Genus, VAI_group) %>%
  summarise(Abundancia_Relativa = mean(Abundancia, na.rm = TRUE), .groups = "drop") %>%
  filter(!is.na(Genus))

# 7. Gráfico
ggplot(abund_por_grupo, aes(x = fct_reorder(Genus, -Abundancia_Relativa), 
                            y = Abundancia_Relativa, fill = VAI_group)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Relative Abundance of Significant Genera by Visceral Adiposity Index (VAI) Group",
       x = "Genus", y = "Relative Abundance") +
  theme_minimal() +
  scale_fill_manual(values = c("#F9A03F", "#D9503F"), name = "Grupo VAI") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



```
#===========================================#
                     TyG
#==========================================#

```{r}
# Carregar pacotes necessários
library(tidyverse)
library(ggplot2)
library(FSA)
library(dplyr)

# 1. Filtrar apenas as amostras com TyG_group definido
dados_tyg <- metadados.saude.alpha %>% 
  filter(!is.na(TyG_group))

# 2. Descobrir quais IDs estão duplicados
duplicados <- dados_tyg$Sample.id[duplicated(dados_tyg$Sample.id)]
print(unique(duplicados))
# [1] "S40061.F00" "S40141.F00"

# Visualizar as duplicatas para inspecionar (opcional)
dados_tyg %>%
  filter(Sample.id %in% c("S40061.F00", "S40141.F00")) %>%
  arrange(Sample.id)

# Remover duplicatas mantendo a primeira ocorrência
dados_tyg <- dados_tyg %>% distinct(Sample.id, .keep_all = TRUE)

# 3. Alinhar os metadados com as colunas da matriz de SVs
# Filtrar para manter só amostras presentes na matriz
dados_tyg <- dados_tyg %>% 
  filter(Sample.id %in% colnames(SVs_filtrado)) %>%
  arrange(match(Sample.id, colnames(SVs_filtrado)))

# Reordenar a matriz SVs de acordo com os metadados
SVs_tyg <- SVs_filtrado[, dados_tyg$Sample.id]

# 4. Calcular abundância relativa (se ainda não estiver feita)
SVs_tyg_rel_filtrado <- sweep(SVs_tyg, 2, colSums(SVs_tyg), FUN = "/")

# Criar vetor de grupos na ordem correta
grupo_tyg <- dados_tyg$TyG_group

# Verificar se o tamanho bate: deve ser 57 (mesmo número de colunas)
if(length(grupo_tyg) != ncol(SVs_tyg_rel_filtrado)) {
  stop("O comprimento de grupo_tyg não bate com o número de amostras na matriz SVs_tyg_rel_filtrado")
}

# 5. Separar as amostras dos grupos "Low" e "High"
SVs_tyg_grupo_low <- SVs_tyg_rel_filtrado[, grupo_tyg == "Low"]
SVs_tyg_grupo_high <- SVs_tyg_rel_filtrado[, grupo_tyg == "High"]

# 6. Calcular médias para cada ASV e log2 Fold Change
media_low <- rowMeans(SVs_tyg_grupo_low)
media_high <- rowMeans(SVs_tyg_grupo_high)

# Adiciona um pseudocount para evitar divisão por zero e log de zero
log2fc <- log2((media_high + 1e-6) / (media_low + 1e-6))

# Calcular p-values para cada ASV com o teste de Wilcoxon
pvalues <- apply(SVs_tyg_rel_filtrado, 1, function(x) {
  grupo1 <- x[grupo_tyg == "Low"]
  grupo2 <- x[grupo_tyg == "High"]
  # Realiza o teste somente se houver variação em ambos os grupos
  if (length(unique(grupo1)) > 1 && length(unique(grupo2)) > 1) {
    wilcox.test(grupo1, grupo2)$p.value
  } else {
    NA  # Caso não haja variação, retorna NA
  }
})

# Criar o dataframe com os resultados
resultado_volcano_tyg <- data.frame(
  ASV = rownames(SVs_tyg_rel_filtrado),
  mean_low = media_low,
  mean_high = media_high,
  log2FoldChange = log2fc,
  pvalue = pvalues
)

# Classificar a significância com base em pvalue bruto
resultado_volcano_tyg <- resultado_volcano_tyg %>%
  mutate(Significativo = ifelse(!is.na(pvalue) & pvalue < 0.05 & abs(log2FoldChange) > 1, "Sim", "Não"))

# Remover linhas com NA em pvalue ou log2FoldChange para plotar
resultado_volcano_tyg_filtrado <- resultado_volcano_tyg %>%
  filter(!is.na(pvalue), !is.na(log2FoldChange))

# 7. Gerar o Volcano Plot sem correção FDR
ggplot(resultado_volcano_tyg_filtrado, aes(x = log2FoldChange, y = -log10(pvalue), color = Significativo)) +
  geom_point(alpha = 0.8, size = 2) +
  scale_color_manual(values = c("Sim" = "red", "Não" = "gray")) +
  geom_vline(xintercept = c(-1, 1), linetype = "dashed", color = "black") +
  geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "black") +
  labs(
    title = "Volcano Plot - Triglyceride-Glucose (TyG) Index Group (pvalue)",
    x = "log2(Fold Change) (High vs Low)",
    y = "-log10(p-valor)",
    color = "Significativo"
  ) +
  theme_minimal(base_size = 14)

```
```{r}
# Supondo que sua tabela de taxonomia se chame 'taxonomy' com coluna 'Feature.ID' e 'Taxon'
resultado_volcano_tyg_tax <- resultado_volcano_tyg %>%
  left_join(taxonomy, by = c("ASV" = "Feature.ID"))

library(tidyr)

resultado_volcano_tyg_tax_sep <- resultado_volcano_tyg_tax %>%
  separate(Taxon, into = c("Domain", "Phylum", "Class", "Order", "Family", "Genus", "Species"),
           sep = ";", fill = "right", remove = FALSE)


```

```{r}
resultado_volcano_tyg_tax_sep <- resultado_volcano_tyg_tax_sep %>%
  mutate(Significativo_pval = ifelse(!is.na(pvalue) & pvalue < 0.05 & abs(log2FoldChange) > 1, "Sim", "Não"))


```
```{r}
resultado_volcano_tyg_tax_sep %>%
  filter(Significativo_pval == "Sim") %>%
  select(ASV, log2FoldChange, pvalue, Phylum, Family, Genus) %>%
  arrange(pvalue)

```

```{r}

library(ggplot2)
library(ggrepel)  # para rótulos que não se sobrepõem

ggplot(resultado_volcano_tyg_tax_sep, aes(x = log2FoldChange, y = -log10(pvalue), color = Significativo_pval)) +
  geom_point(alpha = 0.7, size = 2) +
  scale_color_manual(values = c("Sim" = "red", "Não" = "gray")) +
  geom_vline(xintercept = c(-1, 1), linetype = "dashed", color = "black") +
  geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "black") +
  geom_text_repel(
    data = subset(resultado_volcano_tyg_tax_sep, Significativo_pval == "Sim"),
    aes(label = Genus),
    size = 3,
    max.overlaps = 30
  ) +
  labs(
    title = "Volcano Plot - Triglyceride-Glucose (TyG) Index Group",
    x = "log2(Fold Change) (High vs Low)",
    y = "-log10(p-valor)",
    color = "Significativo"
  ) +
  theme_minimal(base_size = 14)


```
```{r}
# Pegar ASVs significativas
asvs_significativas <- resultado_volcano_tyg_tax_sep %>%
  filter(Significativo_pval == "Sim") %>%
  pull(ASV)

# Filtrar matriz relativa para essas ASVs
SVs_signif <- SVs_tyg_rel_filtrado[asvs_significativas, ]

# Pegar os gêneros correspondentes
generos_signif <- resultado_volcano_tyg_tax_sep %>%
  filter(ASV %in% asvs_significativas) %>%
  select(ASV, Genus) %>%
  mutate(Genus = ifelse(is.na(Genus) | Genus == "", ASV, Genus))  # fallback

# Substituir nomes das linhas por gêneros
rownames(SVs_signif) <- generos_signif$Genus

# Transpor e preparar em formato longo
# 1. Transpor e transformar em data frame
SVs_long <- as.data.frame(t(SVs_signif))

# 2. Adicionar coluna com IDs das amostras
SVs_long$Sample.id <- rownames(SVs_long)

# 3. Passar para formato longo com pivot_longer()
SVs_long <- SVs_long %>%
  pivot_longer(-Sample.id, names_to = "Genus", values_to = "Abundancia")


# Adicionar grupo TyG
SVs_long$TyG_group <- rep(grupo_tyg, each = length(asvs_significativas))




```

```{r}
library(dplyr)

# Média por gênero e grupo
medias <- SVs_long %>%
  group_by(Genus, TyG_group) %>%
  summarise(Abundancia_media = mean(Abundancia), .groups = "drop")

# Gráfico
ggplot(medias, aes(x = reorder(Genus, -Abundancia_media), y = Abundancia_media, fill = TyG_group)) +
  geom_bar(stat = "identity", position = "dodge") +
  coord_flip() +
  labs(title = "Relative Abundance of Significant Genera by Triglyceride-Glucose (TyG) Index Group",
       x = "Genus", y = "Mean Relative Abundance") +
  scale_fill_manual(values = c("Low" = "#1f77b4", "High" = "#ff7f0e")) +
  theme_minimal(base_size = 14)

```
```{r}
library(tidyverse)
library(forcats)

# 1. Garante que Feature.ID está como coluna
df_tyg <- resultado_volcano_tyg_tax_sep %>%
  tibble::as_tibble() %>%
  rename(Feature.ID = ASV)

# 2. Seleciona ASVs significativas pelo p-valor
asvs_significativas <- df_tyg %>%
  filter(Significativo_pval == "Sim") %>%
  pull(Feature.ID)

# 3. Filtrar matriz com ASVs significantes
SVs_sig <- SVs_filtrado[asvs_significativas, ]

# 4. Calcular abundância relativa por amostra
SVs_rel <- sweep(SVs_sig, 2, colSums(SVs_sig), FUN = "/") %>% as.data.frame()

# 5. Reorganizar para formato longo
SVs_long <- SVs_rel %>%
  tibble::rownames_to_column("Feature.ID") %>%
  pivot_longer(-Feature.ID, names_to = "Sample.id", values_to = "Abundancia")

# 6. Adicionar taxonomia e grupo TyG
SVs_long <- SVs_long %>%
  left_join(taxonomy, by = "Feature.ID") %>%
  left_join(metadados.saude.alpha[, c("Sample.id", "TyG_group")], by = "Sample.id") %>%
  mutate(Genus = stringr::str_extract(Taxon, "g__[^;]*")) %>%
  mutate(Genus = gsub("g__", "", Genus)) %>%
  filter(!is.na(TyG_group), !is.na(Genus))

# 7. Calcular média por grupo
abund_por_grupo_tyg <- SVs_long %>%
  group_by(Genus, TyG_group) %>%
  summarise(Abundancia_Relativa = mean(Abundancia, na.rm = TRUE), .groups = "drop")

# 8. Gráfico
ggplot(abund_por_grupo_tyg, aes(x = fct_reorder(Genus, -Abundancia_Relativa), 
                                y = Abundancia_Relativa, fill = TyG_group)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Relative Abundance of Significant Genera by Triglyceride-Glucose (TyG) Index Group",
       x = "Genus", y = "Mean Relative Abundance") +
  theme_minimal(base_size = 13) +
  scale_fill_manual(values = c("Low" = "#D9503F", "High" = "#F9A03F"), name = "TyG Group") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
```{r}



# 1. Seleciona as ASVs significativas do volcano
asvs_signif <- resultado_volcano_tyg_tax_sep %>%
  filter(Significativo == "Sim") %>%
  pull(ASV)

# 2. Filtra o dataframe longo contendo abundâncias por amostra
SVs_box_significativo <- SVs_long %>%
  filter(Feature.ID %in% asvs_signif)

# 3. Cria o gráfico boxplot com facet_wrap por gênero
ggplot(SVs_box_significativo, aes(x = TyG_group, y = Abundancia, fill = TyG_group)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.8) +
  geom_jitter(width = 0.2, size = 1) +
  facet_wrap(~ Genus, scales = "free_y", ncol = 5) +
  stat_compare_means(method = "wilcox.test", label = "p.signif", size = 4) +
  scale_fill_manual(values = c("Low" = "#F9A03F", "High" = "#59C3C3")) +
  labs(
    title = "Significant Genera by Triglyceride-Glucose (TyG) Index Group",
    x = "TyG Group", y = "Mean Relative Abundance", fill = "TyG"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(hjust = 0.5),
    strip.text = element_text(size = 10),
    axis.text.x = element_text(angle = 0),
    plot.margin = margin(10, 20, 20, 10)
  )



```

